{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GFw5rnctwZyq"
   },
   "outputs": [],
   "source": [
    "# train_utils.py\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import math\n",
    "import numpy \n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    '''\n",
    "    Usual Embedding layer with weights multiplied by sqrt(d_model)\n",
    "    '''\n",
    "    def __init__(self,embeddings ,d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        #self.lut = nn.Embedding.from_pretrained(embeddings, freeze=True)\n",
    "        \n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(torch.as_tensor(position.numpy() * div_term.unsqueeze(0).numpy()))\n",
    "        pe[:, 1::2] = torch.cos(torch.as_tensor(position.numpy() * div_term.unsqueeze(0).numpy()))#torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)],\n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ufviw5tGya0o"
   },
   "outputs": [],
   "source": [
    "# config.py\n",
    "\n",
    "class Config(object):\n",
    "    N = 6 #6 in Transformer Paper\n",
    "    d_model = 512 #512 in Transformer Paper\n",
    "    d_ff = 2048 #2048 in Transformer Paper\n",
    "    h = 8\n",
    "    dropout = 0.1\n",
    "    output_size = 4\n",
    "    lr = 0.0003\n",
    "    max_epochs = 200\n",
    "    batch_size = 1\n",
    "    max_sen_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sHtbxK9ByeMy"
   },
   "outputs": [],
   "source": [
    "# attention.py\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Implementation of Scaled dot product attention\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), self.h)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Multi-head attention\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(query, key, value, mask=mask,\n",
    "                                 dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZkwSTpSnxrXW"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    Transformer Encoder\n",
    "\n",
    "    It is a stack of N layers.\n",
    "    '''\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    '''\n",
    "    An encoder layer\n",
    "\n",
    "    Made up of self-attention and a feed forward layer.\n",
    "    Each of these sublayers have residual and layer norm, implemented by SublayerOutput.\n",
    "    '''\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer_output = clones(SublayerOutput(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"Transformer Encoder\"\n",
    "        x = self.sublayer_output[0](x, lambda x: self.self_attn(x, x, x, mask)) # Encoder self-attention\n",
    "        return self.sublayer_output[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Gls8ahWZwxBj"
   },
   "outputs": [],
   "source": [
    "# sublayer.py\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layer normalization module.\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "class SublayerOutput(nn.Module):\n",
    "    '''\n",
    "    A residual connection followed by a layer norm.\n",
    "    '''\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerOutput, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2bbJTlBzxmRV"
   },
   "outputs": [],
   "source": [
    "# feed_forward.py\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Positionwise feed-forward network.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"Implements FFN equation.\"\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('stopwords')\n",
    "def load_data_df(train_file):\n",
    "    with open(train_file,'r') as f:\n",
    "        intents = json.load(f)\n",
    "\n",
    "    patterns = []\n",
    "    tags = []\n",
    "    max_len = 0\n",
    "    for intent in intents['intents']:\n",
    "        \n",
    "        for pattern in intent['patterns']:\n",
    "            if(len(pattern) < max_len):\n",
    "                max_len = len(pattern)\n",
    "            tag = intent['tag']\n",
    "            tags.append(tag)\n",
    "            patterns.append(pattern)\n",
    "\n",
    "    \n",
    "    full_df = pd.DataFrame({\"text\":patterns,\"label\":tags})\n",
    "    #full_df['label'] = full_df['label'].apply(lambda x : x -1)\n",
    "    train, test = train_test_split(full_df, test_size=0.4)\n",
    "    return full_df,train, test , max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XVtqHx44vn2K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('stopwords')\n",
    "def load_data_df(train_file):\n",
    "    with open(train_file,'r') as f:\n",
    "        intents = json.load(f)\n",
    "\n",
    "    patterns = []\n",
    "    tags = []\n",
    "    max_len = 0\n",
    "    for intent in intents['intents']:\n",
    "        \n",
    "        for pattern in intent['patterns']:\n",
    "            if(len(pattern) > max_len):\n",
    "                max_len = len(pattern)\n",
    "            tag = intent['tag']\n",
    "            tags.append(tag)\n",
    "            patterns.append(pattern)\n",
    "\n",
    "\n",
    "    full_df = pd.DataFrame({\"text\":patterns,\"label\":tags})\n",
    "    #full_df['label'] = full_df['label'].apply(lambda x : x -1)\n",
    "    train, test = train_test_split(full_df, test_size=0.4)\n",
    "    return full_df,train, test , max_len\n",
    "\n",
    "\n",
    "# utils.py\n",
    "from torchtext.vocab import FastText\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.full_iterator = None\n",
    "        self.train_iterator = None\n",
    "        self.test_iterator = None\n",
    "        self.val_iterator = None\n",
    "        self.vocab = []\n",
    "        self.word_embeddings = {}\n",
    "        self.output_num = None\n",
    "\n",
    "    def parse_label(self, label):\n",
    "        '''\n",
    "        Get the actual labels from label string\n",
    "        Input:\n",
    "            label (string) : labels of the form '__label__2'\n",
    "        Returns:\n",
    "            label (int) : integer value corresponding to label string\n",
    "        '''\n",
    "        return int(label.strip()[-1])\n",
    "\n",
    "    def get_pandas_df(self, filename):\n",
    "        '''\n",
    "        Load the data into Pandas.DataFrame object\n",
    "        This will be used to convert data to torchtext object\n",
    "        '''\n",
    "        with open(filename, 'r') as datafile:\n",
    "            data = [line.strip().split(',', maxsplit=1) for line in datafile]\n",
    "            data_text = list(map(lambda x: x[1], data))\n",
    "            print(len(data_text))\n",
    "            data_label = list(map(lambda x: self.parse_label(x[0]), data))\n",
    "\n",
    "        full_df = pd.DataFrame({\"text\":data_text, \"label\":data_label})\n",
    "        return full_df\n",
    "\n",
    "    def load_data(self, train_file, test_file=None, val_file=None):\n",
    "        '''\n",
    "        Loads the data from files\n",
    "        Sets up iterators for training, validation and test data\n",
    "        Also create vocabulary and word embeddings based on the data\n",
    "\n",
    "        Inputs:\n",
    "            train_file (String): path to training file\n",
    "            test_file (String): path to test file\n",
    "            val_file (String): path to validation file\n",
    "        '''\n",
    "        # Load data from pd.DataFrame into torchtext.data.Dataset\n",
    "        full_df , train_df , test_df , max_len = load_data_df(train_file)\n",
    "    \n",
    "\n",
    "        NLP = spacy.blank('en')\n",
    "        \n",
    "        tokenizer = lambda sent: [x.text for x in NLP.tokenizer(sent) if x.text != \" \"]\n",
    "\n",
    "        # Creating Field for data\n",
    "        TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True,fix_length=self.config.max_sen_len, include_lengths=False)\n",
    "        LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "        datafields = [(\"text\",TEXT),(\"label\",LABEL)]\n",
    "\n",
    "   \n",
    "        self.output_num = len(full_df.label.unique())\n",
    "\n",
    "        full_examples = [data.Example.fromlist(i, datafields) for i in full_df.values.tolist()]\n",
    "        full_data = data.Dataset(full_examples, datafields)\n",
    "        \n",
    "        train_examples = [data.Example.fromlist(i, datafields) for i in train_df.values.tolist()]\n",
    "        train_data = data.Dataset(train_examples, datafields)\n",
    "\n",
    "\n",
    "        test_examples = [data.Example.fromlist(i, datafields) for i in test_df.values.tolist()]\n",
    "        test_data = data.Dataset(test_examples, datafields)\n",
    "\n",
    "        # If validation file exists, load it. Otherwise get validation data from training data\n",
    "        if val_file:\n",
    "            val_df = self.get_pandas_df(val_file)\n",
    "            val_examples = [data.Example.fromlist(i, datafields) for i in val_df.values.tolist()]\n",
    "            val_data = data.Dataset(val_examples, datafields)\n",
    "        else:\n",
    "            train_data, val_data = train_data.split(split_ratio=0.8)\n",
    "\n",
    "        #TEXT.build_vocab(train_data, vectors=FastText('simple'))\n",
    "        TEXT.build_vocab(full_data, vectors=FastText('simple'))\n",
    "        \n",
    "        #TEXT.build_vocab(train_data,vectors=torchtext.vocab.GloVe(name=\"6B\", dim=300, max_vectors=512),max_size=512, min_freq=2)\n",
    "        self.vocab = TEXT.vocab\n",
    "\n",
    "        self.full_iterator = data.BucketIterator(\n",
    "            (full_data),\n",
    "            batch_size=self.config.batch_size,\n",
    "            sort_key=lambda x: len(x.text),\n",
    "            repeat=False,\n",
    "            shuffle=True)\n",
    "        \n",
    "        self.train_iterator = data.BucketIterator(\n",
    "            (train_data),\n",
    "            batch_size=self.config.batch_size,\n",
    "            sort_key=lambda x: len(x.text),\n",
    "            repeat=False,\n",
    "            shuffle=True)\n",
    "\n",
    "        self.val_iterator, self.test_iterator = data.BucketIterator.splits(\n",
    "            (val_data, test_data),\n",
    "            batch_size=self.config.batch_size,\n",
    "            sort_key=lambda x: len(x.text),\n",
    "            repeat=False,\n",
    "            shuffle=False)\n",
    "        \n",
    "\n",
    "        print (\"Loaded {} training examples\".format(len(train_data)))\n",
    "        print (\"Loaded {} test examples\".format(len(test_data)))\n",
    "        print (\"Loaded {} validation examples\".format(len(val_data)))\n",
    "\n",
    "def evaluate_model(model, iterator):\n",
    "    all_preds = []\n",
    "    all_y = []\n",
    "    for idx,batch in enumerate(iterator):\n",
    "        if torch.cuda.is_available():\n",
    "            x = batch.text.cuda()\n",
    "        else:\n",
    "            x = batch.text\n",
    "        y_pred = model(x)\n",
    "        predicted = torch.max(y_pred.cpu().data, 1)[1] + 1\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_y.extend(batch.label.numpy())\n",
    "    score = accuracy_score(all_y, np.array(all_preds).flatten())\n",
    "    f1 = f1_score(all_y,np.array(all_preds).flatten(), average='macro')\n",
    "    \n",
    "    return score , f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "75lYRgKJxEqD"
   },
   "outputs": [],
   "source": [
    "# Model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config, src_vocab):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        h, N, dropout = self.config.h, self.config.N, self.config.dropout\n",
    "        d_model, d_ff = self.config.d_model, self.config.d_ff\n",
    "\n",
    "        attn = MultiHeadedAttention(h, d_model)\n",
    "        ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        position = PositionalEncoding(d_model, dropout)\n",
    "        self.src_vocab = src_vocab\n",
    "        self.encoder = Encoder(EncoderLayer(config.d_model, deepcopy(attn), deepcopy(ff), dropout), N)\n",
    "        \n",
    "        a = dataset.vocab.vectors.tolist()\n",
    "        for i in range(len(a)):\n",
    "            while(len(a[i])!=config.d_model):\n",
    "                a[i].append(0)\n",
    "                \n",
    "        a= torch.tensor(a)\n",
    "               \n",
    "        self.src_embed = nn.Sequential(Embeddings(dataset.vocab,config.d_model, len(self.src_vocab)), deepcopy(position)) #Embeddings followed by PE\n",
    "\n",
    "        # Fully-Connected Layer\n",
    "        self.fc = nn.Linear(\n",
    "            self.config.d_model,\n",
    "            self.config.output_size\n",
    "        )\n",
    "\n",
    "        # Softmax non-linearity\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):    \n",
    "        \n",
    "        embedded_sents = self.src_embed(x.permute(1,0)) # shape = (batch_size, sen_len, d_model)\n",
    "        \n",
    "        encoded_sents = self.encoder(embedded_sents)\n",
    "\n",
    "        # Convert input to (batch_size, d_model) for linear layer\n",
    "        \n",
    "        \n",
    "        final_feature_map = encoded_sents[:,-1,:]\n",
    "\n",
    "\n",
    "        final_out = self.fc(final_feature_map)\n",
    "        final_out = self.softmax(final_out)\n",
    "        \n",
    "        return final_out\n",
    "\n",
    "    def add_optimizer(self, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def add_loss_op(self, loss_op):\n",
    "        self.loss_op = loss_op\n",
    "\n",
    "    def reduce_lr(self):\n",
    "        print(\"Reducing LR\")\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g['lr'] = g['lr'] / 2\n",
    "    def predict(self,text):\n",
    "        y_pred = self.__call__(text)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def run_epoch(self, train_iterator, val_iterator, epoch):\n",
    "        train_losses = []\n",
    "        val_accuracies = []\n",
    "        losses = []\n",
    "\n",
    "        # Reduce learning rate as number of epochs increase\n",
    "\n",
    "\n",
    "        for i, batch in enumerate(train_iterator):\n",
    "\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                x = batch.text.cuda()\n",
    "                y = (batch.label-1).type(torch.LongTensor)\n",
    "                \n",
    "            else:\n",
    "                x = batch.text\n",
    "                y = (batch.label-1).type(torch.LongTensor)\n",
    "            \n",
    "            y_pred = self.__call__(x)\n",
    "\n",
    "            loss = self.loss_op(y_pred, y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            losses.append(loss.data.cpu().numpy())\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                avg_train_loss = np.mean(losses)\n",
    "                train_losses.append(avg_train_loss)\n",
    "                print(\"\\tAverage training loss: {:.5f}\".format(avg_train_loss))\n",
    "                losses = []\n",
    "\n",
    "                # Evalute Accuracy on validation set\n",
    "                val_accuracy,f1 = evaluate_model(self, val_iterator)\n",
    "                print(\"\\tVal Accuracy: {:.4f}\".format(val_accuracy))\n",
    "                print(\"\\tf1: {:.4f}\".format(f1))\n",
    "                \n",
    "                self.train()\n",
    "\n",
    "        return train_losses, val_accuracies\n",
    "        \n",
    "    def run_epoch2(self, train_iterator,val_iterator,epoch):\n",
    "        losses = []\n",
    "        for j in range(epoch):\n",
    "            for i, batch in enumerate(train_iterator):\n",
    "                if torch.cuda.is_available():\n",
    "                    x = batch.text.cuda()\n",
    "                    y = (batch.label-1).type(torch.LongTensor)                \n",
    "                else:\n",
    "                    x = batch.text\n",
    "                    y = (batch.label-1).type(torch.LongTensor)\n",
    "\n",
    "                y_pred = self.__call__(x)\n",
    "                print([torch.argmax(y_pred, dim=1),y])\n",
    "                loss = self.loss_op(y_pred, y)\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                self.optimizer.step()\n",
    "            losses.append(loss.detach().numpy())  \n",
    "            \n",
    "            if (j+1) % 1 == 0:\n",
    "                print (f'Epoch [{j+1}/{epoch}], Loss: {loss.item():.10f}')\n",
    "                # Evalute Accuracy on validation set\n",
    "                val_accuracy,f1 = evaluate_model(self, val_iterator)\n",
    "                print(\"\\tVal Accuracy: {:.4f}\".format(val_accuracy))\n",
    "                print(\"\\tf1: {:.4f}\".format(f1))\n",
    "                \n",
    "                self.train()\n",
    "                \n",
    "\n",
    "                \n",
    "        return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.iterator.BucketIterator at 0x2998c1c10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.full_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "pyXeQcaLwc9v",
    "outputId": "24d613e9-250d-47f0-bf22-e37aef848d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 41 training examples\n",
      "Loaded 34 test examples\n",
      "Loaded 10 validation examples\n",
      "torch.Size([218, 300])\n",
      "Epoch: 0\n",
      "\tAverage training loss: -0.06690\n",
      "\tVal Accuracy: 0.1000\n",
      "\tf1: 0.0556\n",
      "Epoch: 1\n",
      "\tAverage training loss: -0.02303\n",
      "\tVal Accuracy: 0.1000\n",
      "\tf1: 0.0333\n",
      "Epoch: 2\n",
      "\tAverage training loss: -0.05415\n",
      "\tVal Accuracy: 0.0000\n",
      "\tf1: 0.0000\n",
      "Epoch: 3\n",
      "\tAverage training loss: -0.01947\n",
      "\tVal Accuracy: 0.1000\n",
      "\tf1: 0.0455\n",
      "Epoch: 4\n",
      "\tAverage training loss: -0.95928\n",
      "\tVal Accuracy: 0.3000\n",
      "\tf1: 0.1167\n",
      "Epoch: 5\n",
      "\tAverage training loss: -0.93957\n",
      "\tVal Accuracy: 0.3000\n",
      "\tf1: 0.1182\n",
      "Epoch: 6\n",
      "\tAverage training loss: -0.01709\n",
      "\tVal Accuracy: 0.5000\n",
      "\tf1: 0.3000\n",
      "Epoch: 7\n",
      "\tAverage training loss: -0.99321\n",
      "\tVal Accuracy: 0.6000\n",
      "\tf1: 0.4167\n",
      "Epoch: 8\n",
      "\tAverage training loss: -0.99514\n",
      "\tVal Accuracy: 0.6000\n",
      "\tf1: 0.3939\n",
      "Epoch: 9\n",
      "\tAverage training loss: -0.99902\n",
      "\tVal Accuracy: 0.6000\n",
      "\tf1: 0.3939\n",
      "Epoch: 10\n",
      "\tAverage training loss: -0.99298\n",
      "\tVal Accuracy: 0.6000\n",
      "\tf1: 0.3889\n",
      "Epoch: 11\n",
      "\tAverage training loss: -0.98615\n",
      "\tVal Accuracy: 0.7000\n",
      "\tf1: 0.5152\n",
      "Epoch: 12\n",
      "\tAverage training loss: -0.86887\n",
      "\tVal Accuracy: 0.7000\n",
      "\tf1: 0.5000\n",
      "Epoch: 13\n",
      "\tAverage training loss: -0.99680\n",
      "\tVal Accuracy: 0.7000\n",
      "\tf1: 0.5000\n",
      "Epoch: 14\n",
      "\tAverage training loss: -0.98052\n",
      "\tVal Accuracy: 0.7000\n",
      "\tf1: 0.5000\n",
      "Epoch: 15\n",
      "\tAverage training loss: -0.93661\n",
      "\tVal Accuracy: 0.7000\n",
      "\tf1: 0.5000\n",
      "Epoch: 16\n",
      "\tAverage training loss: -0.94961\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 17\n",
      "\tAverage training loss: -0.99125\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 18\n",
      "\tAverage training loss: -0.92189\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 19\n",
      "\tAverage training loss: -0.98897\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 20\n",
      "\tAverage training loss: -0.88410\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 21\n",
      "\tAverage training loss: -0.98884\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 22\n",
      "\tAverage training loss: -0.99876\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 23\n",
      "\tAverage training loss: -0.99152\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 24\n",
      "\tAverage training loss: -0.99517\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 25\n",
      "\tAverage training loss: -0.99969\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 26\n",
      "\tAverage training loss: -0.99882\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 27\n",
      "\tAverage training loss: -0.99606\n",
      "\tVal Accuracy: 0.9000\n",
      "\tf1: 0.8000\n",
      "Epoch: 28\n",
      "\tAverage training loss: -0.98976\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 29\n",
      "\tAverage training loss: -0.99878\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 30\n",
      "\tAverage training loss: -0.99952\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 31\n",
      "\tAverage training loss: -0.99808\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 32\n",
      "\tAverage training loss: -0.99625\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 33\n",
      "\tAverage training loss: -0.99829\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 34\n",
      "\tAverage training loss: -0.99854\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 35\n",
      "\tAverage training loss: -0.99930\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 36\n",
      "\tAverage training loss: -0.99912\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 37\n",
      "\tAverage training loss: -0.99815\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 38\n",
      "\tAverage training loss: -0.99952\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 39\n",
      "\tAverage training loss: -0.99882\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 40\n",
      "\tAverage training loss: -0.99955\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 41\n",
      "\tAverage training loss: -0.99529\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 42\n",
      "\tAverage training loss: -0.99968\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 43\n",
      "\tAverage training loss: -0.99951\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 44\n",
      "\tAverage training loss: -0.99871\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 45\n",
      "\tAverage training loss: -0.99965\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 46\n",
      "\tAverage training loss: -0.99977\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 47\n",
      "\tAverage training loss: -0.99943\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 48\n",
      "\tAverage training loss: -0.99979\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Epoch: 49\n",
      "\tAverage training loss: -0.99959\n",
      "\tVal Accuracy: 1.0000\n",
      "\tf1: 1.0000\n",
      "Final Training Accuracy: 1.0000\n",
      "Final Training f1: 1.0000\n",
      "Final Validation Accuracy: 1.0000\n",
      "Final Training f1: 1.0000\n",
      "Final Test Accuracy: 1.0000\n",
      "Final Training f1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# import sys  \n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torch\n",
    "import spacy\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "if __name__=='__main__':\n",
    "    config = Config()\n",
    "    config.batch_size =1\n",
    "    config.d_ff = 1024\n",
    "    config.lr = 0.0001\n",
    "    config.max_epochs = 50\n",
    "    dataset = Dataset(config)\n",
    "\n",
    "    train_file = '/Users/mac/Desktop/test/test.json'\n",
    "    dataset.load_data(train_file)\n",
    "    dataset.config.output_size = dataset.output_num\n",
    "\n",
    "    \n",
    "    print(dataset.vocab.vectors.size())\n",
    "    # Create Model with specified optimizer and loss function\n",
    "    ##############################################################\n",
    "\n",
    "    model = Transformer(config, dataset.vocab)\n",
    "    \n",
    "    #for p in model.parameters():\n",
    "     #   if p.dim() > 1: nn.init.xavier_uniform(p)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "    NLLLoss = nn.NLLLoss()\n",
    "    model.add_optimizer(optimizer)\n",
    "    model.add_loss_op(NLLLoss)\n",
    "    ##############################################################\n",
    "\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for i in range(config.max_epochs):\n",
    "        print (\"Epoch: {}\".format(i))\n",
    "        train_loss,val_accuracy = model.run_epoch(dataset.full_iterator, dataset.val_iterator, i)\n",
    "        train_losses.append(train_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    train_acc,train_f1 = evaluate_model(model, dataset.train_iterator)\n",
    "    val_acc,val_f1 = evaluate_model(model, dataset.val_iterator)\n",
    "    test_acc,test_f1 = evaluate_model(model, dataset.test_iterator)\n",
    "\n",
    "    print ('Final Training Accuracy: {:.4f}'.format(train_acc))\n",
    "    print ('Final Training f1: {:.4f}'.format(train_f1))\n",
    "    \n",
    "    print ('Final Validation Accuracy: {:.4f}'.format(val_acc))\n",
    "    print ('Final Training f1: {:.4f}'.format(val_f1))\n",
    "\n",
    "    print ('Final Test Accuracy: {:.4f}'.format(test_acc))\n",
    "    print ('Final Training f1: {:.4f}'.format(test_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses)\n",
    "\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE MODEL\n",
    "\n",
    "torch.save(model, '/Users/mac/Desktop/test/model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0-7): 8 x Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer_output): ModuleList(\n",
       "          (0-1): 2 x SublayerOutput(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (src_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(218, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=24, bias=True)\n",
       "  (softmax): Softmax(dim=None)\n",
       "  (relu): ReLU()\n",
       "  (loss_op): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model= torch.load('/Users/mac/Desktop/test/model.pth')\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "import random\n",
    "import json\n",
    "import spacy\n",
    "def score_words(x,y):\n",
    "  \"\"\" returns the jaccard similarity between two lists \"\"\"\n",
    "  intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "  union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "  return intersection_cardinality/float(union_cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I am Fernando\n",
      "I am here to help you feel free to chat with me:-\n",
      "Let's chat! (type 'quit' to exit)\n",
      "Please write your question with keyword below\n",
      "requirement\n",
      "\n",
      "scholarships\n",
      "\n",
      "batchmates\n",
      "\n",
      "language\n",
      "\n",
      "research topics\n",
      "\n",
      "internship\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bot_name = \"QP\"\n",
    "print(\"Hi! I am Fernando\")\n",
    "print(\"I am here to help you feel free to chat with me:-\")\n",
    "print(\"Let's chat! (type 'quit' to exit)\")\n",
    "print(\"Please write your question with keyword below\")\n",
    "\n",
    "with open('/Users/mac/Desktop/SCIENTIFIC RESEARCH/main QA.json', 'r') as json_data:\n",
    "    main_intents = json.load(json_data)\n",
    "corpse = []\n",
    "responses = []\n",
    "for intent in main_intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    response = intent['responses']\n",
    "    print(tag+\"\\n\")\n",
    "    corpse.append(tag)# here we are appending the word with its tag\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What are the requirements to enter the program?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am token\n",
      "['What', 'are', 'the', 'requirements', 'to', 'enter', 'the', 'program', '?']\n",
      "tensor([[  0,   9,   3, 190,   5,  47,   3,  12,   2,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]])\n",
      "tensor([[9.9983e-01, 3.0584e-06, 2.1754e-06, 2.2673e-06, 1.0296e-07, 2.7802e-06,\n",
      "         3.2193e-07, 1.5170e-07, 2.2775e-05, 1.2512e-06, 5.8468e-08, 2.6065e-05,\n",
      "         5.9985e-05, 7.2376e-06, 2.9579e-06, 2.4742e-05, 9.6218e-06, 2.1956e-08,\n",
      "         1.5403e-07, 5.1320e-06, 2.6572e-08, 1.7471e-06, 2.6738e-08, 1.9814e-07]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor(0.9998, grad_fn=<MaxBackward1>)\n",
      "tensor([1])\n",
      "QP: To enter the program applicants need to: – send a portfolio to the international department with their relevant professional (and academic) CV, transcript of records for their Bachelor's degree, and a proof of their English language proficiency; – pass one of the entrance trials (get a pass mark at the exam): an online theoretical exam on mathematics & programming / Portfolio contest for international applicants / OpenDoors Olympiad for international applicants.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Who will be my batchmates at the program?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am token\n",
      "['Who', 'will', 'be', 'my', 'batchmates', 'at', 'the', 'program', '?']\n",
      "tensor([[  0,  31,  34,  21, 118,  17,   3,  12,   2,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]])\n",
      "tensor([[7.8725e-06, 1.7355e-04, 1.6215e-01, 1.3696e-03, 5.1705e-05, 8.2257e-01,\n",
      "         1.5411e-06, 8.5205e-05, 1.2506e-04, 6.1240e-06, 1.6745e-04, 2.1632e-04,\n",
      "         1.0713e-02, 1.0929e-06, 1.0743e-04, 2.4402e-05, 4.1803e-04, 2.2182e-04,\n",
      "         7.4798e-07, 6.5603e-04, 8.0490e-04, 1.1392e-07, 9.3258e-06, 1.2231e-04]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor(0.8226, grad_fn=<MaxBackward1>)\n",
      "tensor([6])\n",
      "QP: Yes, the most convenient option would be to intern at one of our scientific labs where you will also have a chance to work on your Master's thesis. To know more about how to get internship , please contact the program manager via email: aakarabintseva@itmo.ru (Ms. Alexandra Karabintseva)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Are all courses at the program taught in English?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am token\n",
      "['Are', 'all', 'courses', 'at', 'the', 'program', 'taught', 'in', 'English', '?']\n",
      "tensor([[  0, 109,  43,  17,   3,  12,  99,  15,   0,   2,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]])\n",
      "tensor([[3.8511e-07, 9.7064e-06, 1.9187e-05, 9.9926e-01, 1.6851e-07, 1.7702e-04,\n",
      "         3.1600e-08, 1.6654e-04, 1.6346e-05, 1.8873e-07, 3.7445e-07, 3.1292e-08,\n",
      "         1.2702e-04, 1.1347e-05, 1.4773e-04, 1.3293e-05, 1.2514e-05, 7.6396e-06,\n",
      "         1.1368e-06, 2.5068e-07, 5.3457e-06, 1.4827e-07, 2.0801e-05, 3.1127e-06]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor(0.9993, grad_fn=<MaxBackward1>)\n",
      "tensor([4])\n",
      "QP: Yes, 100% of courses offered at the program are taught in English.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Will I get the chance to do an internship during my studies?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am token\n",
      "['Will', 'I', 'get', 'the', 'chance', 'to', 'do', 'an', 'internship', 'during', 'my', 'studies', '?']\n",
      "tensor([[  0,   0,  23,   3, 121,   5,  14,  39,  33, 134,  21, 198,   2,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]])\n",
      "tensor([[3.6736e-07, 1.3032e-06, 3.5845e-06, 3.8216e-06, 9.0684e-06, 9.9942e-01,\n",
      "         4.4169e-07, 1.6243e-07, 1.4937e-06, 3.9895e-06, 5.2819e-08, 2.2697e-06,\n",
      "         2.0349e-06, 1.3262e-06, 2.0770e-07, 1.7650e-06, 1.9355e-06, 5.1445e-06,\n",
      "         5.0169e-08, 1.0582e-06, 2.9039e-07, 5.1397e-04, 3.2810e-07, 2.3561e-05]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor(0.9994, grad_fn=<MaxBackward1>)\n",
      "tensor([6])\n",
      "QP: Yes, the most convenient option would be to intern at one of our scientific labs where you will also have a chance to work on your Master's thesis. To know more about how to get internship , please contact the program manager via email: aakarabintseva@itmo.ru (Ms. Alexandra Karabintseva)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What is the format of the exam? What are its basic stages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am token\n",
      "['What', 'is', 'the', 'format', 'of', 'the', 'exam', '?', 'What', 'are', 'its', 'basic', 'stages']\n",
      "tensor([[  0,   6,   3,  78,   8,   3,  10,   2,   0,   9, 153, 117, 196,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]])\n",
      "tensor([[4.9757e-06, 1.8886e-06, 1.4969e-06, 6.5117e-07, 7.7515e-07, 2.8281e-07,\n",
      "         9.9718e-01, 6.5599e-06, 9.9475e-08, 2.9878e-07, 2.5700e-06, 2.6129e-03,\n",
      "         6.6145e-07, 9.5039e-05, 4.9010e-09, 2.2958e-05, 7.7028e-06, 1.6345e-06,\n",
      "         4.7202e-06, 4.8505e-05, 3.8141e-08, 7.8762e-07, 9.0480e-07, 3.3903e-07]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor(0.9972, grad_fn=<MaxBackward1>)\n",
      "tensor([7])\n",
      "QP: At the exam you will get 2 exam questions from the list (1st from section 1 and the 2nd from section 2). You will have 60 minutes to write the answers and then you will answer your questions before the examination board. During the interview examiners may ask additional questions on each topic for your examination ticket if needed. The evaluated results are presented to applicants in the next 1-2 working days via email. The exam will be held in Zoom. Please make sure you have a stable internet connection and a working microphone & webcam.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  how to get internship\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am token\n",
      "['how', 'to', 'get', 'internship']\n",
      "tensor([[11,  5, 23, 33,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])\n",
      "tensor([[1.4289e-06, 4.2460e-06, 2.6554e-08, 1.9843e-07, 1.1167e-06, 1.0795e-05,\n",
      "         3.1221e-06, 3.5604e-08, 7.5255e-07, 2.9133e-06, 1.2760e-08, 2.1534e-06,\n",
      "         3.8711e-08, 9.5829e-05, 1.2974e-07, 2.1718e-06, 3.7228e-07, 9.5755e-07,\n",
      "         2.4102e-07, 4.5083e-08, 6.6531e-08, 9.9987e-01, 2.2132e-07, 1.8277e-06]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor(0.9999, grad_fn=<MaxBackward1>)\n",
      "tensor([22])\n",
      "QP: To know more about how to get internship , please contact the program manager via email: aakarabintseva@itmo.ru (Ms. Alexandra Karabintseva)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  is there alternative of exam to study in this program\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am token\n",
      "['is', 'there', 'alternative', 'of', 'exam', 'to', 'study', 'in', 'this', 'program']\n",
      "tensor([[ 6, 16,  0,  8, 10,  5, 53, 15, 28, 12,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])\n",
      "tensor([[1.2151e-04, 9.3029e-04, 4.7205e-05, 3.9080e-06, 4.6801e-04, 3.6335e-04,\n",
      "         1.7719e-06, 3.3384e-02, 3.5605e-04, 1.4749e-05, 9.6908e-04, 1.1382e-01,\n",
      "         7.9663e-01, 8.0654e-03, 4.4383e-02, 2.5848e-04, 1.1858e-05, 9.6805e-07,\n",
      "         6.6110e-07, 8.7068e-07, 1.2427e-04, 4.4955e-05, 4.7350e-06, 1.2416e-06]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor(0.7966, grad_fn=<MaxBackward1>)\n",
      "tensor([13])\n",
      "QP: The program content is available in the web-page: https://en.itmo.ru/en/viewjep/2/5/Big_Data_and_Machine_Learning.htm.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  when is exam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am token\n",
      "['when', 'is', 'exam']\n",
      "tensor([[19,  6, 10,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])\n",
      "tensor([[5.7710e-05, 9.2018e-06, 1.9865e-05, 8.6930e-06, 1.7373e-06, 7.0310e-06,\n",
      "         2.3249e-01, 1.2305e-03, 1.9581e-05, 2.4046e-06, 1.4755e-04, 4.4838e-02,\n",
      "         3.7897e-07, 3.6763e-06, 2.1817e-07, 1.0059e-03, 6.9714e-04, 4.8826e-06,\n",
      "         2.2002e-04, 7.1917e-01, 3.9365e-06, 2.9654e-05, 4.8784e-06, 2.7745e-05]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor(0.7192, grad_fn=<MaxBackward1>)\n",
      "tensor([20])\n",
      "QP: The exams are being held from March 1st to August 25th 2023. If you want to know the date of the nearest exam, please contact the program manager via email: aakarabintseva@itmo.ru (Ms. Alexandra Karabintseva)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import regexp_tokenize\n",
    "def tokenize(sentence):\n",
    "    return regexp_tokenize(sentence, pattern=\"\\w+\")\n",
    "\n",
    "while True:\n",
    "    sentence = input(\"You: \")\n",
    "    if(any(sentence.lower()==item.lower() for item in [\"quit\",\"finish\",\"over\",\"bye\",\"goodbye\"])):\n",
    "        print(f\"{bot_name}: Goodbye , have a nice day\")\n",
    "        break\n",
    "\n",
    "    similarity = []\n",
    "    for i in corpse:\n",
    "        similarity.append(score_words(sentence,i))\n",
    "    #print(similarity)\n",
    "    \n",
    "    if(max(similarity) > 0.5 and len(tokenize(sentence))==1 ):\n",
    "        print(f\"{bot_name}: \"+responses[similarity.index(max(similarity))][0])\n",
    "    else:\n",
    "    ## tensor part\n",
    "        \n",
    "        NLP = spacy.blank(\"en\")\n",
    "        tokenizer = lambda sent: [x.text for x in NLP.tokenizer(sent) if x.text != \" \"]\n",
    "        token = tokenizer(sentence)\n",
    "        sequenced=[]\n",
    "        for i in range(len(token)):\n",
    "            sequenced.append(model.src_vocab[token[i]])\n",
    "\n",
    "        while(len(sequenced)!=model.config.max_sen_len):\n",
    "            sequenced.append(1)\n",
    "        \n",
    "        array = np.array(sequenced)\n",
    "        \n",
    "        transposed_array = array.T\n",
    "        sequenced = transposed_array.tolist()\n",
    "        tensor = []\n",
    "        tensor.append(sequenced)\n",
    "        print('i am token')\n",
    "        print(token)\n",
    "        user_input = torch.tensor(tensor)\n",
    "        print(user_input)\n",
    "        user_input = user_input.permute(1,0)\n",
    "\n",
    "        output = model.predict(user_input)\n",
    "        print(output)\n",
    "        prob = output.max() \n",
    "        print(prob)\n",
    "        output = torch.argmax(output, dim=1)\n",
    "\n",
    "        output = output + 1\n",
    "        print(output)\n",
    "        \n",
    "        \n",
    "        ##\n",
    "        with open('/Users/mac/Desktop/test/test.json', 'r') as json_data:\n",
    "            intents = json.load(json_data)\n",
    "        if prob > 0.1:\n",
    "                for intent in intents['intents']:\n",
    "                    if output == intent[\"tag\"]:\n",
    "                        print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "        else:\n",
    "            print(f\"{bot_name}: Sorry I am unable to Process Your Request\")\n",
    "            print(f\"{bot_name}: You may find the way forward in https://en.itmo.ru/en/viewjep/2/5/Big_Data_and_Machine_Learning.htm\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
